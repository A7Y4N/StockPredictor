{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85a0d63f-d9b2-4f8d-b81e-020c3a1fe124",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 16:49:48.356 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-12 16:49:48.390 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /Users/aryanharish/miniforge3/envs/mlproject/lib/python3.12/site-packages/ipykernel_launcher.py [ARGUMENTS]\n",
      "2026-01-12 16:49:48.390 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-12 16:49:48.390 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-12 16:49:48.391 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-12 16:49:48.395 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-12 16:49:48.395 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-12 16:49:48.395 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    },
    {
     "ename": "UnpicklingError",
     "evalue": "Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n\tWeightsUnpickler error: Unsupported global: GLOBAL sklearn.preprocessing._data.StandardScaler was not an allowed global by default. Please use `torch.serialization.add_safe_globals([sklearn.preprocessing._data.StandardScaler])` or the `torch.serialization.safe_globals([sklearn.preprocessing._data.StandardScaler])` context manager to allowlist this global if you trust this class/function.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnpicklingError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 48\u001b[39m\n\u001b[32m     45\u001b[39m     scaler = checkpoint[\u001b[33m'\u001b[39m\u001b[33mscaler\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     46\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m model, scaler\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m model, scaler = \u001b[43mload_assets\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[38;5;66;03m# --- 3. STREAMLIT UI ---\u001b[39;00m\n\u001b[32m     51\u001b[39m st.title(\u001b[33m\"\u001b[39m\u001b[33mðŸ“ˆ Stock Price Predictor (LSTM)\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/mlproject/lib/python3.12/site-packages/streamlit/runtime/caching/cache_utils.py:228\u001b[39m, in \u001b[36mCachedFunc.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    225\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    226\u001b[39m         spinner_message = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRunning `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m(...)`.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m228\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_or_create_cached_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspinner_message\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/mlproject/lib/python3.12/site-packages/streamlit/runtime/caching/cache_utils.py:270\u001b[39m, in \u001b[36mCachedFunc._get_or_create_cached_value\u001b[39m\u001b[34m(self, func_args, func_kwargs, spinner_message)\u001b[39m\n\u001b[32m    264\u001b[39m spinner_or_no_context = (\n\u001b[32m    265\u001b[39m     spinner(spinner_message, _cache=\u001b[38;5;28;01mTrue\u001b[39;00m, show_time=\u001b[38;5;28mself\u001b[39m._info.show_time)\n\u001b[32m    266\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m spinner_message \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_nested_cache_function\n\u001b[32m    267\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m contextlib.nullcontext()\n\u001b[32m    268\u001b[39m )\n\u001b[32m    269\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m spinner_or_no_context:\n\u001b[32m--> \u001b[39m\u001b[32m270\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handle_cache_miss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/mlproject/lib/python3.12/site-packages/streamlit/runtime/caching/cache_utils.py:329\u001b[39m, in \u001b[36mCachedFunc._handle_cache_miss\u001b[39m\u001b[34m(self, cache, value_key, func_args, func_kwargs)\u001b[39m\n\u001b[32m    325\u001b[39m \u001b[38;5;66;03m# We acquired the lock before any other thread. Compute the value!\u001b[39;00m\n\u001b[32m    326\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._info.cached_message_replay_ctx.calling_cached_function(\n\u001b[32m    327\u001b[39m     \u001b[38;5;28mself\u001b[39m._info.func\n\u001b[32m    328\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m329\u001b[39m     computed_value = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_info\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    331\u001b[39m \u001b[38;5;66;03m# We've computed our value, and now we need to write it back to the cache\u001b[39;00m\n\u001b[32m    332\u001b[39m \u001b[38;5;66;03m# along with any \"replay messages\" that were generated during value computation.\u001b[39;00m\n\u001b[32m    333\u001b[39m messages = \u001b[38;5;28mself\u001b[39m._info.cached_message_replay_ctx._most_recent_messages\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 31\u001b[39m, in \u001b[36mload_assets\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;129m@st\u001b[39m.cache_resource\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_assets\u001b[39m():\n\u001b[32m     30\u001b[39m     \u001b[38;5;66;03m# Load the bundle you created\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m     checkpoint = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mfull_pipeline.pth\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcpu\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m     \u001b[38;5;66;03m# Reconstruct Model\u001b[39;00m\n\u001b[32m     34\u001b[39m     config = checkpoint[\u001b[33m'\u001b[39m\u001b[33mconfig\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/mlproject/lib/python3.12/site-packages/torch/serialization.py:1529\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[39m\n\u001b[32m   1521\u001b[39m                 \u001b[38;5;28;01mreturn\u001b[39;00m _load(\n\u001b[32m   1522\u001b[39m                     opened_zipfile,\n\u001b[32m   1523\u001b[39m                     map_location,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1526\u001b[39m                     **pickle_load_args,\n\u001b[32m   1527\u001b[39m                 )\n\u001b[32m   1528\u001b[39m             \u001b[38;5;28;01mexcept\u001b[39;00m pickle.UnpicklingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m-> \u001b[39m\u001b[32m1529\u001b[39m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle.UnpicklingError(_get_wo_message(\u001b[38;5;28mstr\u001b[39m(e))) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1530\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m _load(\n\u001b[32m   1531\u001b[39m             opened_zipfile,\n\u001b[32m   1532\u001b[39m             map_location,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1535\u001b[39m             **pickle_load_args,\n\u001b[32m   1536\u001b[39m         )\n\u001b[32m   1537\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mmap:\n",
      "\u001b[31mUnpicklingError\u001b[39m: Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n\tWeightsUnpickler error: Unsupported global: GLOBAL sklearn.preprocessing._data.StandardScaler was not an allowed global by default. Please use `torch.serialization.add_safe_globals([sklearn.preprocessing._data.StandardScaler])` or the `torch.serialization.safe_globals([sklearn.preprocessing._data.StandardScaler])` context manager to allowlist this global if you trust this class/function.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html."
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# --- 1. MODEL DEFINITION ---\n",
    "# Must be identical to your training script\n",
    "class PredictionModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, output_dim):\n",
    "        super(PredictionModel, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "# --- 2. LOAD THE BUNDLE ---\n",
    "@st.cache_resource\n",
    "def load_assets():\n",
    "    # Load the bundle you created\n",
    "    checkpoint = torch.load('full_pipeline.pth', map_location=torch.device('cpu'))\n",
    "    \n",
    "    # Reconstruct Model\n",
    "    config = checkpoint['config']\n",
    "    model = PredictionModel(\n",
    "        config['input_dim'], \n",
    "        config['hidden_dim'], \n",
    "        config['num_layers'], \n",
    "        config['output_dim']\n",
    "    )\n",
    "    model.load_state_dict(checkpoint['model_state'])\n",
    "    model.eval()\n",
    "    \n",
    "    # Load Scaler\n",
    "    scaler = checkpoint['scaler']\n",
    "    return model, scaler\n",
    "\n",
    "model, scaler = load_assets()\n",
    "\n",
    "# --- 3. STREAMLIT UI ---\n",
    "st.title(\"ðŸ“ˆ Stock Price Predictor (LSTM)\")\n",
    "st.sidebar.header(\"Settings\")\n",
    "\n",
    "ticker = st.sidebar.text_input(\"Enter Stock Ticker\", value=\"AAPL\")\n",
    "start_date = st.sidebar.date_input(\"Start Date\", value=pd.to_datetime(\"2020-01-07\"))\n",
    "\n",
    "if st.button(\"Predict\"):\n",
    "    with st.spinner(f\"Fetching data for {ticker}...\"):\n",
    "        # Fetch fresh data\n",
    "        df = yf.download(ticker, start=start_date)\n",
    "        \n",
    "        if df.empty:\n",
    "            st.error(\"No data found for this ticker.\")\n",
    "        else:\n",
    "            # Data Preprocessing\n",
    "            close_prices = df[['Close']].copy()\n",
    "            scaled_data = scaler.transform(close_prices)\n",
    "            \n",
    "            # Prepare sequences (30 days lookback like your model)\n",
    "            seq_length = 30\n",
    "            if len(scaled_data) < seq_length:\n",
    "                st.warning(f\"Not enough data for prediction. Need at least {seq_length} days.\")\n",
    "            else:\n",
    "                # Prepare the last 30 days to predict the current price\n",
    "                # Or prepare all sequences to show the graph comparison\n",
    "                sequences = []\n",
    "                for i in range(len(scaled_data) - seq_length):\n",
    "                    sequences.append(scaled_data[i : i + seq_length])\n",
    "                \n",
    "                X = torch.tensor(np.array(sequences), dtype=torch.float32)\n",
    "                \n",
    "                # Prediction\n",
    "                with torch.no_grad():\n",
    "                    y_pred_scaled = model(X)\n",
    "                \n",
    "                y_pred = scaler.inverse_transform(y_pred_scaled.numpy())\n",
    "                actual = close_prices.values[seq_length:]\n",
    "\n",
    "                # --- 4. VISUALIZATION ---\n",
    "                st.subheader(f\"Prediction Results for {ticker}\")\n",
    "                \n",
    "                fig, ax = plt.subplots(figsize=(12, 6))\n",
    "                dates = df.index[seq_length:]\n",
    "                ax.plot(dates, actual, label=\"Actual Price\", color=\"blue\")\n",
    "                ax.plot(dates, y_pred, label=\"Predicted Price\", color=\"green\", linestyle=\"--\")\n",
    "                ax.set_xlabel(\"Date\")\n",
    "                ax.set_ylabel(\"Price\")\n",
    "                ax.legend()\n",
    "                st.pyplot(fig)\n",
    "\n",
    "                # Show latest prediction\n",
    "                current_price = actual[-1][0]\n",
    "                predicted_price = y_pred[-1][0]\n",
    "                col1, col2 = st.columns(2)\n",
    "                col1.metric(\"Current Price\", f\"${current_price:.2f}\")\n",
    "                col2.metric(\"Model Prediction\", f\"${predicted_price:.2f}\", \n",
    "                            delta=f\"{(predicted_price - current_price):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950f347c-b4e3-46b8-af31-88f3f578c876",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
